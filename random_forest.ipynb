{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>cloudCover</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>icon</th>\n",
       "      <th>precipAccumulation</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>precipProbability</th>\n",
       "      <th>precipType</th>\n",
       "      <th>pressure</th>\n",
       "      <th>...</th>\n",
       "      <th>Glo Mod (Wh/m^2)</th>\n",
       "      <th>Glo Mod Unc (%)</th>\n",
       "      <th>Dir Mod (Wh/m^2)</th>\n",
       "      <th>Dir Mod Unc (%)</th>\n",
       "      <th>Dif Mod (Wh/m^2)</th>\n",
       "      <th>Dif Mod Unc (%)</th>\n",
       "      <th>clear_sky</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>avg_last_week</th>\n",
       "      <th>last_week_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-02 00:00:00</th>\n",
       "      <td>36.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>31.40</td>\n",
       "      <td>0.81</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1022.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 01:00:00</th>\n",
       "      <td>35.79</td>\n",
       "      <td>0.22</td>\n",
       "      <td>30.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>clear-night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1022.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 02:00:00</th>\n",
       "      <td>35.67</td>\n",
       "      <td>0.32</td>\n",
       "      <td>30.43</td>\n",
       "      <td>0.81</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1023.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 03:00:00</th>\n",
       "      <td>35.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>30.64</td>\n",
       "      <td>0.82</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1023.57</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 04:00:00</th>\n",
       "      <td>35.66</td>\n",
       "      <td>0.88</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1023.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     apparentTemperature  cloudCover  dewPoint  humidity  \\\n",
       "2006-01-02 00:00:00                36.81        0.82     31.40      0.81   \n",
       "2006-01-02 01:00:00                35.79        0.22     30.80      0.82   \n",
       "2006-01-02 02:00:00                35.67        0.32     30.43      0.81   \n",
       "2006-01-02 03:00:00                35.49        0.50     30.64      0.82   \n",
       "2006-01-02 04:00:00                35.66        0.88     31.25      0.84   \n",
       "\n",
       "                                    icon  precipAccumulation  precipIntensity  \\\n",
       "2006-01-02 00:00:00  partly-cloudy-night                 NaN              0.0   \n",
       "2006-01-02 01:00:00          clear-night                 NaN              0.0   \n",
       "2006-01-02 02:00:00  partly-cloudy-night                 NaN              0.0   \n",
       "2006-01-02 03:00:00  partly-cloudy-night                 NaN              0.0   \n",
       "2006-01-02 04:00:00  partly-cloudy-night                 NaN              0.0   \n",
       "\n",
       "                     precipProbability precipType  pressure        ...         \\\n",
       "2006-01-02 00:00:00                0.0        NaN   1022.75        ...          \n",
       "2006-01-02 01:00:00                0.0        NaN   1022.80        ...          \n",
       "2006-01-02 02:00:00                0.0        NaN   1023.57        ...          \n",
       "2006-01-02 03:00:00                0.0        NaN   1023.57        ...          \n",
       "2006-01-02 04:00:00                0.0        NaN   1023.31        ...          \n",
       "\n",
       "                    Glo Mod (Wh/m^2)  Glo Mod Unc (%)  Dir Mod (Wh/m^2)  \\\n",
       "2006-01-02 00:00:00                0                0                 0   \n",
       "2006-01-02 01:00:00                0                0                 0   \n",
       "2006-01-02 02:00:00                0                0                 0   \n",
       "2006-01-02 03:00:00                0                0                 0   \n",
       "2006-01-02 04:00:00                0                0                 0   \n",
       "\n",
       "                     Dir Mod Unc (%)  Dif Mod (Wh/m^2)  Dif Mod Unc (%)  \\\n",
       "2006-01-02 00:00:00                0                 0                0   \n",
       "2006-01-02 01:00:00                0                 0                0   \n",
       "2006-01-02 02:00:00                0                 0                0   \n",
       "2006-01-02 03:00:00                0                 0                0   \n",
       "2006-01-02 04:00:00                0                 0                0   \n",
       "\n",
       "                     clear_sky  yesterday  avg_last_week  last_week_median  \n",
       "2006-01-02 00:00:00        0.0        0.0            NaN               0.0  \n",
       "2006-01-02 01:00:00        0.0        0.0            NaN               0.0  \n",
       "2006-01-02 02:00:00        0.0        0.0            NaN               0.0  \n",
       "2006-01-02 03:00:00        0.0        0.0            NaN               0.0  \n",
       "2006-01-02 04:00:00        0.0        0.0            NaN               0.0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newark_df = pd.read_csv('./data/merged/newark_merged.csv', index_col='Unnamed: 0')\n",
    "newark_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['apparentTemperature', 'cloudCover', 'dewPoint', 'humidity', 'icon',\n",
       "       'precipAccumulation', 'precipIntensity', 'precipProbability',\n",
       "       'precipType', 'pressure', 'summary', 'temperature', 'uvIndex',\n",
       "       'visibility', 'windBearing', 'windGust', 'windSpeed', 'ETR (Wh/m^2)',\n",
       "       'ETRN (Wh/m^2)', 'Glo Mod (Wh/m^2)', 'Glo Mod Unc (%)',\n",
       "       'Dir Mod (Wh/m^2)', 'Dir Mod Unc (%)', 'Dif Mod (Wh/m^2)',\n",
       "       'Dif Mod Unc (%)', 'clear_sky', 'yesterday', 'avg_last_week',\n",
       "       'last_week_median'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newark_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Drop as these columns have a ton of NaNs and are columns of strings.\n",
    "newark_df = newark_df.drop(columns=[\"precipAccumulation\", \"precipType\", \"windGust\", \"icon\", \"summary\", \"ETR (Wh/m^2)\", \"ETRN (Wh/m^2)\", \"Dir Mod (Wh/m^2)\", \"Dif Mod (Wh/m^2)\", 'Glo Mod Unc (%)', 'Dir Mod Unc (%)', 'Dif Mod Unc (%)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "apparentTemperature      0\n",
       "cloudCover               0\n",
       "dewPoint                 0\n",
       "humidity                 0\n",
       "precipIntensity          0\n",
       "precipProbability        0\n",
       "pressure                 0\n",
       "temperature              0\n",
       "uvIndex                  0\n",
       "visibility               0\n",
       "windBearing              0\n",
       "windSpeed                0\n",
       "Glo Mod (Wh/m^2)         0\n",
       "clear_sky                0\n",
       "yesterday                0\n",
       "avg_last_week          145\n",
       "last_week_median         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure only avg last week is na\n",
    "newark_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>cloudCover</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>precipProbability</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>uvIndex</th>\n",
       "      <th>visibility</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>Glo Mod (Wh/m^2)</th>\n",
       "      <th>clear_sky</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>avg_last_week</th>\n",
       "      <th>last_week_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-02 00:00:00</th>\n",
       "      <td>36.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>31.40</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.75</td>\n",
       "      <td>36.81</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>246</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 01:00:00</th>\n",
       "      <td>35.79</td>\n",
       "      <td>0.22</td>\n",
       "      <td>30.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.80</td>\n",
       "      <td>35.79</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>234</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 02:00:00</th>\n",
       "      <td>35.67</td>\n",
       "      <td>0.32</td>\n",
       "      <td>30.43</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1023.57</td>\n",
       "      <td>35.67</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>216</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 03:00:00</th>\n",
       "      <td>35.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>30.64</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1023.57</td>\n",
       "      <td>35.49</td>\n",
       "      <td>0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>225</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 04:00:00</th>\n",
       "      <td>35.66</td>\n",
       "      <td>0.88</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1023.31</td>\n",
       "      <td>35.66</td>\n",
       "      <td>0</td>\n",
       "      <td>9.68</td>\n",
       "      <td>216</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     apparentTemperature  cloudCover  dewPoint  humidity  \\\n",
       "2006-01-02 00:00:00                36.81        0.82     31.40      0.81   \n",
       "2006-01-02 01:00:00                35.79        0.22     30.80      0.82   \n",
       "2006-01-02 02:00:00                35.67        0.32     30.43      0.81   \n",
       "2006-01-02 03:00:00                35.49        0.50     30.64      0.82   \n",
       "2006-01-02 04:00:00                35.66        0.88     31.25      0.84   \n",
       "\n",
       "                     precipIntensity  precipProbability  pressure  \\\n",
       "2006-01-02 00:00:00              0.0                0.0   1022.75   \n",
       "2006-01-02 01:00:00              0.0                0.0   1022.80   \n",
       "2006-01-02 02:00:00              0.0                0.0   1023.57   \n",
       "2006-01-02 03:00:00              0.0                0.0   1023.57   \n",
       "2006-01-02 04:00:00              0.0                0.0   1023.31   \n",
       "\n",
       "                     temperature  uvIndex  visibility  windBearing  windSpeed  \\\n",
       "2006-01-02 00:00:00        36.81        0       10.00          246       1.75   \n",
       "2006-01-02 01:00:00        35.79        0       10.00          234       1.86   \n",
       "2006-01-02 02:00:00        35.67        0       10.00          216       1.55   \n",
       "2006-01-02 03:00:00        35.49        0        9.74          225       0.81   \n",
       "2006-01-02 04:00:00        35.66        0        9.68          216       0.63   \n",
       "\n",
       "                     Glo Mod (Wh/m^2)  clear_sky  yesterday  avg_last_week  \\\n",
       "2006-01-02 00:00:00                 0        0.0        0.0            NaN   \n",
       "2006-01-02 01:00:00                 0        0.0        0.0            NaN   \n",
       "2006-01-02 02:00:00                 0        0.0        0.0            NaN   \n",
       "2006-01-02 03:00:00                 0        0.0        0.0            NaN   \n",
       "2006-01-02 04:00:00                 0        0.0        0.0            NaN   \n",
       "\n",
       "                     last_week_median  \n",
       "2006-01-02 00:00:00               0.0  \n",
       "2006-01-02 01:00:00               0.0  \n",
       "2006-01-02 02:00:00               0.0  \n",
       "2006-01-02 03:00:00               0.0  \n",
       "2006-01-02 04:00:00               0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newark_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_test_split_df(df):\n",
    "    test_size = 0.2\n",
    "    random_state = 32\n",
    "\n",
    "    df = df.dropna()\n",
    "    X = df.drop(columns=['Glo Mod (Wh/m^2)'])\n",
    "    y = df['Glo Mod (Wh/m^2)']\n",
    "    test_length = int(test_size*len(X))\n",
    "    X_train, X_test, y_train, y_test = X.iloc[0:-1*test_length], X.iloc[-1*test_length:], y[0:-1*test_length], y[-1*test_length:]\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=random_state)\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_test_split_df(newark_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score:  0.984760488348628\n",
      "Validation Score:  0.9202953841162536\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "rfr.fit(X_train, y_train)\n",
    "\n",
    "rfr_train_score = rfr.score(X_train, y_train)\n",
    "rfr_val_score = rfr.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', rfr_train_score)\n",
    "print('Validation Score: ', rfr_val_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To visualize what features are used for the largest splits, let's restrict the depth of the decision trees and visualize a tree with graphviz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr_limited_depth = RandomForestRegressor(max_depth=4)\n",
    "rfr_limited_depth.fit(X_train, y_train)\n",
    "\n",
    "# Extract single tree\n",
    "estimator = rfr_limited_depth.estimators_[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Luckily, we can copy the code and visualize the tree on Webgraphviz. By running the following cell, you'll see a pretty long output -- follow the link and copy and paste the output to get a visualization of the decision tree we fit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "digraph Tree {\n",
      "node [shape=box] ;\n",
      "0 [label=\"uvIndex <= 1.5\\nmse = 61989.109\\nsamples = 24648\\nvalue = 165.273\"] ;\n",
      "1 [label=\"avg_last_week <= 101.643\\nmse = 8432.719\\nsamples = 17847\\nvalue = 43.41\"] ;\n",
      "0 -> 1 [labeldistance=2.5, labelangle=45, headlabel=\"True\"] ;\n",
      "2 [label=\"avg_last_week <= 34.214\\nmse = 547.332\\nsamples = 14518\\nvalue = 7.527\"] ;\n",
      "1 -> 2 ;\n",
      "3 [label=\"avg_last_week <= 8.786\\nmse = 30.558\\nsamples = 13259\\nvalue = 1.367\"] ;\n",
      "2 -> 3 ;\n",
      "4 [label=\"mse = 2.123\\nsamples = 12592\\nvalue = 0.345\"] ;\n",
      "3 -> 4 ;\n",
      "5 [label=\"mse = 176.4\\nsamples = 667\\nvalue = 20.603\"] ;\n",
      "3 -> 5 ;\n",
      "6 [label=\"avg_last_week <= 66.643\\nmse = 1425.527\\nsamples = 1259\\nvalue = 71.539\"] ;\n",
      "2 -> 6 ;\n",
      "7 [label=\"mse = 612.11\\nsamples = 647\\nvalue = 53.784\"] ;\n",
      "6 -> 7 ;\n",
      "8 [label=\"mse = 1607.8\\nsamples = 612\\nvalue = 89.382\"] ;\n",
      "6 -> 8 ;\n",
      "9 [label=\"cloudCover <= 0.835\\nmse = 12436.265\\nsamples = 3329\\nvalue = 202.043\"] ;\n",
      "1 -> 9 ;\n",
      "10 [label=\"clear_sky <= 738.764\\nmse = 10595.043\\nsamples = 2228\\nvalue = 241.232\"] ;\n",
      "9 -> 10 ;\n",
      "11 [label=\"mse = 4430.919\\nsamples = 1267\\nvalue = 187.384\"] ;\n",
      "10 -> 11 ;\n",
      "12 [label=\"mse = 9574.49\\nsamples = 961\\nvalue = 315.583\"] ;\n",
      "10 -> 12 ;\n",
      "13 [label=\"cloudCover <= 0.975\\nmse = 6534.908\\nsamples = 1101\\nvalue = 121.227\"] ;\n",
      "9 -> 13 ;\n",
      "14 [label=\"mse = 9035.171\\nsamples = 328\\nvalue = 162.441\"] ;\n",
      "13 -> 14 ;\n",
      "15 [label=\"mse = 4458.4\\nsamples = 773\\nvalue = 103.819\"] ;\n",
      "13 -> 15 ;\n",
      "16 [label=\"uvIndex <= 4.5\\nmse = 61370.628\\nsamples = 6801\\nvalue = 484.826\"] ;\n",
      "0 -> 16 [labeldistance=2.5, labelangle=-45, headlabel=\"False\"] ;\n",
      "17 [label=\"cloudCover <= 0.795\\nmse = 35235.505\\nsamples = 4276\\nvalue = 368.999\"] ;\n",
      "16 -> 17 ;\n",
      "18 [label=\"avg_last_week <= 358.357\\nmse = 23515.764\\nsamples = 2771\\nvalue = 451.823\"] ;\n",
      "17 -> 18 ;\n",
      "19 [label=\"mse = 15618.571\\nsamples = 1175\\nvalue = 384.515\"] ;\n",
      "18 -> 19 ;\n",
      "20 [label=\"mse = 23577.719\\nsamples = 1596\\nvalue = 500.572\"] ;\n",
      "18 -> 20 ;\n",
      "21 [label=\"cloudCover <= 0.995\\nmse = 21050.521\\nsamples = 1505\\nvalue = 217.0\"] ;\n",
      "17 -> 21 ;\n",
      "22 [label=\"mse = 27656.681\\nsamples = 585\\nvalue = 287.094\"] ;\n",
      "21 -> 22 ;\n",
      "23 [label=\"mse = 11746.794\\nsamples = 920\\nvalue = 172.459\"] ;\n",
      "21 -> 23 ;\n",
      "24 [label=\"cloudCover <= 0.295\\nmse = 43355.683\\nsamples = 2525\\nvalue = 684.749\"] ;\n",
      "16 -> 24 ;\n",
      "25 [label=\"uvIndex <= 6.5\\nmse = 15571.935\\nsamples = 1246\\nvalue = 779.368\"] ;\n",
      "24 -> 25 ;\n",
      "26 [label=\"mse = 12064.493\\nsamples = 549\\nvalue = 705.067\"] ;\n",
      "25 -> 26 ;\n",
      "27 [label=\"mse = 10077.722\\nsamples = 697\\nvalue = 841.171\"] ;\n",
      "25 -> 27 ;\n",
      "28 [label=\"cloudCover <= 0.655\\nmse = 53236.988\\nsamples = 1279\\nvalue = 589.794\"] ;\n",
      "24 -> 28 ;\n",
      "29 [label=\"mse = 44566.385\\nsamples = 883\\nvalue = 642.454\"] ;\n",
      "28 -> 29 ;\n",
      "30 [label=\"mse = 52717.936\\nsamples = 396\\nvalue = 473.343\"] ;\n",
      "28 -> 30 ;\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import graphviz\n",
    "from sklearn import tree\n",
    "\n",
    "print(tree.export_graphviz(estimator, feature_names=X_train.columns, out_file=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that uvIndex, avg_last_week, clear_sky, and cloudCover are among the most important features for this one tree as they result in the best splits of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0, 944,   0, ...,   0,  88,   0])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_train).reshape(y_train.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_features': 'auto', 'n_estimators': 101, 'min_samples_split': 20, 'max_depth': 9}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 1, stop = 101, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(start = 1, stop = 9, num = 2)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [20, 100, 150, 200]\n",
    "# Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "# Create the random grid\n",
    "param_dict = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rfr, param_distributions = param_dict, n_iter = 10, cv = 10, random_state=42)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, np.array(y_train).reshape(y_train.shape[0]))\n",
    "\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 121, stop = 151, num = 5)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(start = 1, stop = 9, num = 2)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 10, 15, 20]\n",
    "# Minimum number of samples required at each leaf node\n",
    "# min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True]\n",
    "# Create the random grid\n",
    "param_dict = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "#                'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rfr, param_distributions = param_dict, n_iter = 20, cv = 10, random_state=42)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, np.array(y_train).reshape(y_train.shape[0]))\n",
    "\n",
    "print(rf_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# With best params found above\n",
    "rfr_tree = RandomForestRegressor(n_estimators=151, min_samples_split=2, max_features='sqrt', max_depth=None, bootstrap=True)\n",
    "rfr_tree.fit(X_train, y_train)\n",
    "\n",
    "rfr_train_score = rfr_tree.score(X_train, y_train)\n",
    "rfr_val_score = rfr_tree.score(X_val, y_val)\n",
    "\n",
    "print('Train Score: ', rfr_train_score)\n",
    "print('Validation Score: ', rfr_val_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forests for the other 4 locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def define_forest(n_estimators, max_depth, min_samples_split): \n",
    "    # Fit tree with best newark params as a starting point.\n",
    "    rfr_tree = RandomForestRegressor(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, bootstrap=True, max_features='sqrt')\n",
    "    rfr_tree.fit(X_train, y_train)\n",
    "    \n",
    "    train_score = rfr_tree.score(X_train, y_train)\n",
    "    val_score = rfr_tree.score(X_val, y_val)\n",
    "\n",
    "    print('Train Score: ', train_score)\n",
    "    print('Validation Score: ', val_score)\n",
    "\n",
    "    importances = sorted((100 / max(rfr_tree.feature_importances_)) * rfr_tree.feature_importances_)\n",
    "\n",
    "    im_df = pd.DataFrame({'Feature': X_train.columns, 'Importance': importances})\n",
    "    im_df = im_df.sort_values(by=\"Importance\", ascending=False)\n",
    "    im_df.plot.bar(x='Feature', y='Importance')\n",
    "    plt.show()\n",
    "\n",
    "    return rfr_tree\n",
    "\n",
    "def get_rfr(loc_name):\n",
    "    merged = pd.read_csv('./data/merged/' + loc_name + '_merged.csv', index_col='Unnamed: 0')\n",
    "    merged = merged.drop(columns=[\"precipAccumulation\", \"precipType\", \"windGust\", \"icon\", \"summary\", \"ETR (Wh/m^2)\", \"ETRN (Wh/m^2)\", \"Dir Mod (Wh/m^2)\", \"Dif Mod (Wh/m^2)\", \"cloudCoverError\"])\n",
    "    merged = merged.dropna(thresh=len(merged) - 150, axis=1)\n",
    "    print(merged.shape)\n",
    "    X_train, y_train, X_val, y_val, X_test, y_test = train_test_split_df(merged)\n",
    "    print(X_train.shape)\n",
    "\n",
    "    # Number of trees in random forest\n",
    "    n_estimators = [int(x) for x in np.linspace(start = 121, stop = 151, num = 5)]\n",
    "    # Number of features to consider at every split\n",
    "    max_features = ['sqrt']\n",
    "    # Maximum number of levels in tree\n",
    "    max_depth = [int(x) for x in np.linspace(start = 9, stop = 13, num = 2)]\n",
    "    max_depth.append(None)\n",
    "    # Minimum number of samples required to split a node\n",
    "    min_samples_split = [2, 10, 15]\n",
    "    # Minimum number of samples required at each leaf node\n",
    "    # min_samples_leaf = [1, 2, 4]\n",
    "    # Method of selecting samples for training each tree\n",
    "    bootstrap = [True]\n",
    "    # Create the random grid\n",
    "    param_dict = {'n_estimators': n_estimators,\n",
    "                   'max_features': max_features,\n",
    "                   'max_depth': max_depth,\n",
    "                   'min_samples_split': min_samples_split,\n",
    "    #                'min_samples_leaf': min_samples_leaf,\n",
    "                   'bootstrap': bootstrap}\n",
    "\n",
    "    rf_random = RandomizedSearchCV(estimator = rfr, param_distributions = param_dict, n_iter = 10, cv = 10, random_state=42)\n",
    "    # Fit the random search model\n",
    "    rf_random.fit(X_train, np.array(y_train).reshape(y_train.shape[0]))\n",
    "\n",
    "    print(rf_random.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jfk_rfr = get_rfr(\"jfk\")\n",
    "bridgeport_rfr = get_rfr(\"bridgeport\")\n",
    "laguardia_rfr = get_rfr(\"laguardia\")\n",
    "li_macarthur_rfr = get_rfr(\"li_macarthur\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We notice that last week median is overwhelmingly and consistently the most prominent feature used to predict solar irradiance (Glo Mod (Wh/m^2)).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

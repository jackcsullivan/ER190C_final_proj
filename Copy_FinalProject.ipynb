{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Knowledge is Power: Predicting Solar Energy in Time and Space\n",
    "\n",
    "Fall, 2018\n",
    "\n",
    "John Leyden\n",
    "\n",
    "Jack Sullivan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Project Requirements (delete this markdown cell in your final submission)\n",
    "\n",
    "**How to use this notebook**:  This notebook is the template for your semester project.  Each markdown cell provides instructions on what to do in order to do a successful project.  The cell you're reading right now is the only one you can delete from what you eventually hand in.  For the other cells:\n",
    "1. You may replace the instructions in each cell with your own work but do not edit the cell titles (with the exception of the project title, above).  \n",
    "2. Follow the instructions in each section carefully.  For some sections you will enter only markdown text in the existing cells. For other sections, you'll accompany the markdown cells with additional code cells, and perhaps more markdown, before moving on to the next section.  \n",
    "\n",
    "**Grading**.  You'll see point allocations listed in each of the section titles below.  In addition, there are other categories for points: \n",
    "1. Visualization (10 points).  Well organized plots and legible plots get high points, as do beautiful and innovative plots.  \n",
    "2. Clarity (5 points). Note that clarity also supports points elsewhere, because if we can't understand what you're explaining, we'll assume you didn't understand what you were doing and give points accordingly!  \n",
    "\n",
    "For each Section or Category, we will give points according to the following percentage scale:\n",
    "1. More than 90%:  work that is free of anything but superficial mistakes, and demonstrates creativity and / or a very deep understanding of what you are doing.\n",
    "2. 80-90%: work without fundamental errors and demonstrates a basic understanding of what you're doing.\n",
    "3. 60-80%: work with fundamental flaws in the analysis and / or conveys that you do not understand the basics of the work you are trying to do.\n",
    "4. Below 60%: Work that is severely lacking or incomplete.  \n",
    "\n",
    "Note that we distinguish *mistakes* from *\"my idea didn't work\"*.  Sometimes you don't know if you can actually do the thing you're trying to do and as you dig in you find that you can't.  That doesn't necessarily mean you made a mistake; it might just mean you needed more information.  We'll still give  high marks to ambitious projects that \"fail\" at their stated objective, as long as that objective was clear and you understood what you were doing.  \n",
    "\n",
    "**Advice on working in groups:**  We encourage group work.  However to create a level playing field for groups with varying size, we have the following requirements:\n",
    "1. Projects must have at least one distinct quantitative question per student in the group.  Questions can and should be related, but they need to require distinct work efforts, and the interpretation and analysis should cover each question in detail.  If you have any doubt about whether your questions are distinct, consult with the instructors.\n",
    "2. We use a sliding data requirements scale, see below.\n",
    "\n",
    "**Data requirements**:  Projects must use data from a minimum of $1+N_s$ different sources, where $N_s$ is the number of students in the group.  You should merge at least two data sets.  \n",
    "\n",
    "**Advice on Project Topics**:  We want you to do a project that relates to energy and environment topics.  However this is not a hard requirement.\n",
    "\n",
    "**Suggested data sets**:  These are just some ideas for starting points.  You can definitely bring your own data to the table!\n",
    "1. [Purple Air](https://www.purpleair.com) (suprise!).  Instructions on how to download PurpleAir data are [here](https://docs.google.com/document/d/15ijz94dXJ-YAZLi9iZ_RaBwrZ4KtYeCy08goGBwnbCU/edit).\n",
    "2. California Enviroscreen database.  Available [here].(https://oehha.ca.gov/calenviroscreen/report/calenviroscreen-30) \n",
    "3. Several data sets available from the UC Irvine machine learning library:\n",
    "    1. [Forest Fires](https://archive.ics.uci.edu/ml/datasets/Forest+Fires)\n",
    "    4. [Climate](https://archive.ics.uci.edu/ml/datasets/Greenhouse+Gas+Observing+Network)\n",
    "    5. [Ozone](https://archive.ics.uci.edu/ml/datasets/Ozone+Level+Detection)\n",
    "4. California Solar Initiative data (installed rooftop solar systems).  Available [here](https://www.californiasolarstatistics.ca.gov/data_downloads/).\n",
    "5. World Bank Open Data, available [here](https://data.worldbank.org).\n",
    "6. California ISO monitored emissions data, [here](http://www.caiso.com/TodaysOutlook/Pages/Emissions.aspx).\n",
    "\n",
    "**Dates**:\n",
    "You have three due dates:\n",
    "1. November 19, in lab.  In this lab you'll be expected to have formed groups (if you wish), identified your data sources, done preliminary exploratory data analysis, and decided on a forecasting question.  The instructors will circulate through the room and discuss your progress on the project.  Your progress will constitute part of your grade for that week's lab. \n",
    "2. Novbember 26, in lab.  In this lab you'll be expected to have done some initial forecasting work: build and fit a model, test its accuracy, plot its performance.\n",
    "3. December 11, 6pm: This is when your final project is due.  You will submit your notebook and data to bCourses or GitHub (to be determined).  \n",
    "\n",
    "Ok, now on to the project!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract (5 points)\n",
    "Although this section comes first, you'll write it last.  It should be a ~250 word summary of your project.  1/3rd of the abstract should provide background, 1/3rd should explain what you did, and 1/3rd should explain what you learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Background (5 points)\n",
    "In this section you will describe relevant background for your project.  It should give enough information that a non-expert can understand in detail the history and / or context of the system or setting you wish to study, the need for quantitative analysis, and, broadly, what impact a quantitative analyses could have on the system.  Shoot for 500 words here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Question (5 points)\n",
    "In this section you will pose the central question or questions for your semester project.  Questions should be extremely clear, well-defined and answerable with a numeric value or TRUE / FALSE answer.  If you seek to make a TRUE / FALSE decision, you must clearly state a priori what quantitative criteria you'll use to make that decision.  \n",
    "\n",
    "You should reflect here on why it's important to answer these questions.  In most cases this will mean that you'll frame the answers to your questions as informing one or more *resource allocation* problems.  If you have done a good job of providing project background (in the cell above) then this reflection will be short and easy to write.\n",
    "\n",
    "**Comment on novelty:** You may find it hard to identify a project question that has *never* been answered before.  It's ok if you take inspiration from existing analyses.  However you shouldn't exactly reproduce someone else's analysis.  If you take inspiration from another analyses, you should still use different models, different data, and so on.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input Data Description (5 points)\n",
    "Here you will provide an initial description of your data sets, including:\n",
    "1. The origins of your data.  Where did you get the data?  How were the data collected from the original sources?\n",
    "2. The structure, granularity, scope, temporality and faithfulness (SGSTF) of your data.  To discuss these attributes you should load the data into one or more data frames (so you'll start building code cells for the first time).  At a minimum, use some basic methods (`.head`, `.loc`, and so on) to provide support for the descriptions you provide for SGSTF. \n",
    "\n",
    "[Chapter 5](https://www.textbook.ds100.org/ch/05/eda_intro.html) of the DS100 textbook might be helpful for you in this section.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Observed Insolation\n",
    "### National Solar Radiation Database, National Renewable Energy Laboratory (NREL)\n",
    "The NSRDB is a free collection of datasets containing meteorological and solar irradience data. This database supports programs for the U.S. Department of Energy, research, and the general public. NREL's physical solar models are constructed from stations that sense solar irradience, which is our target variable. The stations are located throughout the U.S. \n",
    "\n",
    "<img src=\"./images/map.png\" alt=\"map\" width=\"500\"/>\n",
    "\n",
    "The data can be accessed [here](https://rredc.nrel.gov/solar/old_data/nsrdb/1991-2010/). After downloading stations in the tri-state area, we read them from a csv:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YYYY-MM-DD</th>\n",
       "      <th>HH:MM (LST)</th>\n",
       "      <th>Zenith (deg)</th>\n",
       "      <th>Azimuth (deg)</th>\n",
       "      <th>ETR (Wh/m^2)</th>\n",
       "      <th>ETRN (Wh/m^2)</th>\n",
       "      <th>Glo Mod (Wh/m^2)</th>\n",
       "      <th>Glo Mod Unc (%)</th>\n",
       "      <th>Glo Mod Source</th>\n",
       "      <th>Dir Mod (Wh/m^2)</th>\n",
       "      <th>...</th>\n",
       "      <th>Ceil Hgt (m)</th>\n",
       "      <th>Ceil Hgt Flg</th>\n",
       "      <th>Liq Precip Depth (mm)</th>\n",
       "      <th>Liq Precip Depth Flg</th>\n",
       "      <th>Liq Precip Quantity (hours)</th>\n",
       "      <th>Liq Precip Quantity Flg</th>\n",
       "      <th>Precip Wat (cm)</th>\n",
       "      <th>Precip Wat Flg</th>\n",
       "      <th>AOD (unitless)</th>\n",
       "      <th>AOD Flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>1:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>99</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>2:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1.5</td>\n",
       "      <td>51</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>3:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1.5</td>\n",
       "      <td>51</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>4:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>5:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>152</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1.4</td>\n",
       "      <td>51</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YYYY-MM-DD HH:MM (LST)  Zenith (deg)  Azimuth (deg)  ETR (Wh/m^2)  \\\n",
       "0  2010-01-01        1:00          99.0          -99.0             0   \n",
       "1  2010-01-01        2:00          99.0          -99.0             0   \n",
       "2  2010-01-01        3:00          99.0          -99.0             0   \n",
       "3  2010-01-01        4:00          99.0          -99.0             0   \n",
       "4  2010-01-01        5:00          99.0          -99.0             0   \n",
       "\n",
       "   ETRN (Wh/m^2)  Glo Mod (Wh/m^2)  Glo Mod Unc (%)  Glo Mod Source  \\\n",
       "0              0                 0                0               2   \n",
       "1              0                 0                0               2   \n",
       "2              0                 0                0               2   \n",
       "3              0                 0                0               2   \n",
       "4              0                 0                0               2   \n",
       "\n",
       "   Dir Mod (Wh/m^2)   ...     Ceil Hgt (m)  Ceil Hgt Flg  \\\n",
       "0                 0   ...              213             5   \n",
       "1                 0   ...              213             5   \n",
       "2                 0   ...              213             5   \n",
       "3                 0   ...              213             5   \n",
       "4                 0   ...              152             5   \n",
       "\n",
       "   Liq Precip Depth (mm)  Liq Precip Depth Flg  Liq Precip Quantity (hours)  \\\n",
       "0                      3                     1                            6   \n",
       "1                      0                     5                            1   \n",
       "2                      0                     5                            1   \n",
       "3                      0                     5                            1   \n",
       "4                      0                     5                            1   \n",
       "\n",
       "   Liq Precip Quantity Flg  Precip Wat (cm)  Precip Wat Flg  AOD (unitless)  \\\n",
       "0                       99              1.5               3           0.088   \n",
       "1                       99              1.5              51           0.088   \n",
       "2                       99              1.5              51           0.088   \n",
       "3                       99              1.5               3           0.088   \n",
       "4                       99              1.4              51           0.088   \n",
       "\n",
       "   AOD Flg  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read in Newark Airport data for 2010\n",
    "ewr_2010 = pd.read_csv('./data/station_solar/NSRDB_StationData_19910101_20101231_725020/NSRDB_StationData_20100101_20101231_725020.csv')\n",
    "ewr_2010.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Success! We've found our target variable: **Glo Mod (Wh/m^2)**. NREL describes this as *\"Total amount of direct and diffuse solar radiation received on a horizontal surface during the 60-minute period ending at the timestamp\"*\n",
    "\n",
    "**Structure:** For each chosen station, we download a directory of Comma Seperated Files, one file for each year from 1990-2010. \n",
    "\n",
    "**Granularity:** The temporal granularity is one hour, and the spatial granularity is latitude/longitude to four decimal places.\n",
    "\n",
    "**Scope:** The temporal scope is 1990-2010. The spatial scope is every point on the map pictured above. We choose 5 class 1 stations in the New York City area for our first question. We choose 11 class 1 & 2 stations in the New York City area for our second question.\n",
    "\n",
    "**Temporality:** There is one column for day in YYYY-MM-DD format. For each date, there are 24 rows (one for each hour) represented in HH:MM format.\n",
    "\n",
    "**Faithfullness:** According to the NSRDB User Manual (linked below), the class 1 stations that we use are 100% certain for years 2006-2010. Class 2 stations have slightly less certainty. In general, we consider NSRDB reliable because they are used by various government and research institutions, including the US Department of Energy, Solar Consulting Services, the University of Oregon, and the University of Wisconsin. Also, we re-affirm faithfullness with sanity-check visualizations, which can be seen in the visualization section.\n",
    "\n",
    "More information about NSRDB can be found in the user manual [here](https://www.nrel.gov/docs/fy12osti/54824.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# One sanity check\n",
    "plt.figure(figsize=(8, 5))\n",
    "all_noons = ewr_2010[ewr_2010['HH:MM (LST)'] == '12:00']\n",
    "plt.scatter(range(len(all_noons)), all_noons['Glo Mod (Wh/m^2)'])\n",
    "plt.ylabel('Irradience at Noon')\n",
    "plt.xlabel('Day of Year');\n",
    "plt.title('Sanity Check');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The point-wise maximum of the scatterplot follows the pattern of summer and winter sunlight. We also observe that there is variation below the point-wise maximum, likeley due to weather or air quality variation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Historical and Forecasted Weather\n",
    "### Dark Sky API, Dark Sky Company, LLC.\n",
    "\n",
    "The Dark Sky API is a free REST API that provides weather data for any lat/lon in the US for a given day. We use the Time Machine Request, with this description: *A Time Machine Request returns the observed (in the past) or forecasted (in the future) hour-by-hour weather and daily weather conditions for a particular date. * ([Documentation](https://darksky.net/dev/docs#time-machine-request))\n",
    "\n",
    "We create a function using the python library `requests` to gather the data. Then, we use `pd.DataFrame` to transorm the JSON into a dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>cloudCover</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>icon</th>\n",
       "      <th>ozone</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>precipProbability</th>\n",
       "      <th>precipType</th>\n",
       "      <th>pressure</th>\n",
       "      <th>summary</th>\n",
       "      <th>temperature</th>\n",
       "      <th>uvIndex</th>\n",
       "      <th>visibility</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>windGust</th>\n",
       "      <th>windSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-12-01 00:00:00</th>\n",
       "      <td>39.33</td>\n",
       "      <td>1.00</td>\n",
       "      <td>34.64</td>\n",
       "      <td>0.83</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>269.43</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.78</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>39.33</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>319</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01 01:00:00</th>\n",
       "      <td>39.15</td>\n",
       "      <td>0.99</td>\n",
       "      <td>34.33</td>\n",
       "      <td>0.83</td>\n",
       "      <td>cloudy</td>\n",
       "      <td>268.30</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1019.89</td>\n",
       "      <td>Overcast</td>\n",
       "      <td>39.15</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>334</td>\n",
       "      <td>2.49</td>\n",
       "      <td>2.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01 02:00:00</th>\n",
       "      <td>38.07</td>\n",
       "      <td>0.73</td>\n",
       "      <td>33.80</td>\n",
       "      <td>0.84</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>267.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020.16</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>38.07</td>\n",
       "      <td>0</td>\n",
       "      <td>9.54</td>\n",
       "      <td>352</td>\n",
       "      <td>2.28</td>\n",
       "      <td>2.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01 03:00:00</th>\n",
       "      <td>36.94</td>\n",
       "      <td>0.23</td>\n",
       "      <td>32.58</td>\n",
       "      <td>0.84</td>\n",
       "      <td>clear-night</td>\n",
       "      <td>267.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020.20</td>\n",
       "      <td>Clear</td>\n",
       "      <td>36.94</td>\n",
       "      <td>0</td>\n",
       "      <td>8.86</td>\n",
       "      <td>349</td>\n",
       "      <td>2.34</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-01 04:00:00</th>\n",
       "      <td>35.65</td>\n",
       "      <td>0.05</td>\n",
       "      <td>31.68</td>\n",
       "      <td>0.85</td>\n",
       "      <td>clear-night</td>\n",
       "      <td>267.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1020.53</td>\n",
       "      <td>Clear</td>\n",
       "      <td>35.65</td>\n",
       "      <td>0</td>\n",
       "      <td>8.64</td>\n",
       "      <td>357</td>\n",
       "      <td>2.18</td>\n",
       "      <td>1.54</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     apparentTemperature  cloudCover  dewPoint  humidity  \\\n",
       "2018-12-01 00:00:00                39.33        1.00     34.64      0.83   \n",
       "2018-12-01 01:00:00                39.15        0.99     34.33      0.83   \n",
       "2018-12-01 02:00:00                38.07        0.73     33.80      0.84   \n",
       "2018-12-01 03:00:00                36.94        0.23     32.58      0.84   \n",
       "2018-12-01 04:00:00                35.65        0.05     31.68      0.85   \n",
       "\n",
       "                                    icon   ozone  precipIntensity  \\\n",
       "2018-12-01 00:00:00               cloudy  269.43              0.0   \n",
       "2018-12-01 01:00:00               cloudy  268.30              0.0   \n",
       "2018-12-01 02:00:00  partly-cloudy-night  267.89              0.0   \n",
       "2018-12-01 03:00:00          clear-night  267.75              0.0   \n",
       "2018-12-01 04:00:00          clear-night  267.64              0.0   \n",
       "\n",
       "                     precipProbability precipType  pressure        summary  \\\n",
       "2018-12-01 00:00:00                0.0        NaN   1019.78       Overcast   \n",
       "2018-12-01 01:00:00                0.0        NaN   1019.89       Overcast   \n",
       "2018-12-01 02:00:00                0.0        NaN   1020.16  Mostly Cloudy   \n",
       "2018-12-01 03:00:00                0.0        NaN   1020.20          Clear   \n",
       "2018-12-01 04:00:00                0.0        NaN   1020.53          Clear   \n",
       "\n",
       "                     temperature  uvIndex  visibility  windBearing  windGust  \\\n",
       "2018-12-01 00:00:00        39.33        0       10.00          319      2.68   \n",
       "2018-12-01 01:00:00        39.15        0       10.00          334      2.49   \n",
       "2018-12-01 02:00:00        38.07        0        9.54          352      2.28   \n",
       "2018-12-01 03:00:00        36.94        0        8.86          349      2.34   \n",
       "2018-12-01 04:00:00        35.65        0        8.64          357      2.18   \n",
       "\n",
       "                     windSpeed  \n",
       "2018-12-01 00:00:00       2.43  \n",
       "2018-12-01 01:00:00       2.33  \n",
       "2018-12-01 02:00:00       2.04  \n",
       "2018-12-01 03:00:00       2.00  \n",
       "2018-12-01 04:00:00       1.54  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "def get_epoch(timestamp_str, tz='US/Pacific'):\n",
    "    ts = pd.Timestamp(timestamp_str,  tz=tz)\n",
    "    return int(ts.value / (1*10**9))\n",
    "\n",
    "def get_hourly_weather(lat, lon, timestamp_str, tz='US/Pacific', key='c75fe89710b37b9fd1531010a8968ef1'):\n",
    "    base_url = 'https://api.darksky.net/forecast/' + key + '/'\n",
    "    with_location = base_url + str(lat) + ',' + str(lon)\n",
    "    epoch = get_epoch(timestamp_str, tz)\n",
    "    with_time = with_location + ',' + str(epoch)\n",
    "    resp = requests.get(with_time)\n",
    "    if resp.status_code != 200:\n",
    "        raise RuntimeError('API call errored with code: ' + resp.status_code)\n",
    "    data_dict = resp.json()\n",
    "    daterange = pd.date_range(timestamp_str, periods=24, freq='1H')\n",
    "    df = pd.DataFrame(data_dict['hourly']['data'])\n",
    "    df.index = daterange\n",
    "    df = df.drop(columns=['time'])\n",
    "    return df\n",
    "\n",
    "# Lets look at EWR on December 1, 2018\n",
    "lat = 40.717\n",
    "lon = -74.183\n",
    "timestamp_str = \"2018-12-01 00:00:00\"\n",
    "tz = 'US/Eastern'\n",
    "ewr_weather = get_hourly_weather(lat, lon, timestamp_str, tz)\n",
    "ewr_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Structure:** The response is JSON, including a list of hourly data that contains fields like `cloudCover` and `humidity`. The entire json response example can be seen [here](https://darksky.net/dev/docs#time-machine-request).\n",
    "\n",
    "**Granularity:** The temporal granularity is one hour, and the spatial granularity is latitude/longitude to 3 decimal places.\n",
    "\n",
    "**Scope:** The temporal scope covers at least as early as 1990 for all locations. The spatial scope is global. However, the website says *Historical data availability varies depending on whether we have access to weather station data for a given place and time*\n",
    "\n",
    "**Temporality:** The time is recorded in `epoch`, which is defined as *seconds after Thursday, Jan 1, 1970*\n",
    "\n",
    "**Faithfullness:** Darksky is used by a variety of reputable organizations, including Microsoft, Yelp, and the Caltech Jet Propulsion Laboratory. It also uses reliable sources for data, such as NOAA and [others](https://darksky.net/dev/docs/sources). We will cross-reference with Accuweather below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44.82"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cross-referece \n",
    "max(ewr_weather['temperature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to [AccuWeather](https://www.accuweather.com/en/us/newark-nj/07102/december-weather/349530), the max temp for Dec. 1 was 46 degrees! Pretty close!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeled Direct Sunlight\n",
    "### Pysolar, pingswept et. al."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeled Global Horizontal Sunlight\n",
    "### Physical Solar Model, National Renewable Energy Laboratory (NREL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning (10 points)\n",
    "In this section you will walk through the data cleaning and merging process.  Explain how you make decisions to clean and merge the data.  Explain how you convince yourself that the data don't contain problems that will limit your ability to produce a meaningful analysis from them.  \n",
    "\n",
    "[Chapter 4](https://www.textbook.ds100.org/ch/04/cleaning_intro.html) of the DS100 textbook might be helpful to you in this section.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observed Insolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to have our solar data in a useable and mergable state, we need to pull it in, and preprocess the solar data. We first pull in the data with ```get_raw_solar_df(location_id)``` from the ```data/station_solar/``` directory that has all of the raw solar station data. The raw data has a file for each year, so we concatenate the data from the years of 2006-2010 into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_raw_solar_df(location_id):\n",
    "    df = pd.DataFrame()\n",
    "    for year in range(2006, 2011):\n",
    "        year_df = pd.read_csv(\"data/station_solar/NSRDB_StationData_19910101_20101231_\" + str(location_id) +\"/NSRDB_StationData_\" + str(year) +\"0101_\" + str(year) +\"1231_\" + str(location_id) +\".csv\")\n",
    "        df = pd.concat([df, year_df])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use newark as our example again and check the head of the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YYYY-MM-DD</th>\n",
       "      <th>HH:MM (LST)</th>\n",
       "      <th>Zenith (deg)</th>\n",
       "      <th>Azimuth (deg)</th>\n",
       "      <th>ETR (Wh/m^2)</th>\n",
       "      <th>ETRN (Wh/m^2)</th>\n",
       "      <th>Glo Mod (Wh/m^2)</th>\n",
       "      <th>Glo Mod Unc (%)</th>\n",
       "      <th>Glo Mod Source</th>\n",
       "      <th>Dir Mod (Wh/m^2)</th>\n",
       "      <th>...</th>\n",
       "      <th>Ceil Hgt (m)</th>\n",
       "      <th>Ceil Hgt Flg</th>\n",
       "      <th>Liq Precip Depth (mm)</th>\n",
       "      <th>Liq Precip Depth Flg</th>\n",
       "      <th>Liq Precip Quantity (hours)</th>\n",
       "      <th>Liq Precip Quantity Flg</th>\n",
       "      <th>Precip Wat (cm)</th>\n",
       "      <th>Precip Wat Flg</th>\n",
       "      <th>AOD (unitless)</th>\n",
       "      <th>AOD Flg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>1:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1.2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>2:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4572</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1.2</td>\n",
       "      <td>51</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>3:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>22000</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1.1</td>\n",
       "      <td>51</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>4:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1219</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2006-01-01</td>\n",
       "      <td>5:00</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-99.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1158</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>99</td>\n",
       "      <td>1.1</td>\n",
       "      <td>51</td>\n",
       "      <td>0.088</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YYYY-MM-DD HH:MM (LST)  Zenith (deg)  Azimuth (deg)  ETR (Wh/m^2)  \\\n",
       "0  2006-01-01        1:00          99.0          -99.0             0   \n",
       "1  2006-01-01        2:00          99.0          -99.0             0   \n",
       "2  2006-01-01        3:00          99.0          -99.0             0   \n",
       "3  2006-01-01        4:00          99.0          -99.0             0   \n",
       "4  2006-01-01        5:00          99.0          -99.0             0   \n",
       "\n",
       "   ETRN (Wh/m^2)  Glo Mod (Wh/m^2)  Glo Mod Unc (%)  Glo Mod Source  \\\n",
       "0              0                 0                0               2   \n",
       "1              0                 0                0               2   \n",
       "2              0                 0                0               2   \n",
       "3              0                 0                0               2   \n",
       "4              0                 0                0               2   \n",
       "\n",
       "   Dir Mod (Wh/m^2)   ...     Ceil Hgt (m)  Ceil Hgt Flg  \\\n",
       "0                 0   ...            22000             1   \n",
       "1                 0   ...             4572             5   \n",
       "2                 0   ...            22000             5   \n",
       "3                 0   ...             1219             5   \n",
       "4                 0   ...             1158             5   \n",
       "\n",
       "   Liq Precip Depth (mm)  Liq Precip Depth Flg  Liq Precip Quantity (hours)  \\\n",
       "0                      0                     5                            1   \n",
       "1                      0                     5                            1   \n",
       "2                      0                     5                            1   \n",
       "3                      0                     5                            1   \n",
       "4                      0                     5                            1   \n",
       "\n",
       "   Liq Precip Quantity Flg  Precip Wat (cm)  Precip Wat Flg  AOD (unitless)  \\\n",
       "0                       99              1.2               3           0.088   \n",
       "1                       99              1.2              51           0.088   \n",
       "2                       99              1.1              51           0.088   \n",
       "3                       99              1.1               3           0.088   \n",
       "4                       99              1.1              51           0.088   \n",
       "\n",
       "   AOD Flg  \n",
       "0        1  \n",
       "1        1  \n",
       "2        1  \n",
       "3        1  \n",
       "4        1  \n",
       "\n",
       "[5 rows x 49 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newark_df = get_raw_solar_df(725020)\n",
    "newark_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the columns, we only want to keep the ```'YYYY-MM-DD', 'HH:MM (LST)', 'Glo Mod (Wh/m^2)'``` columns as we will get weather data from a separate source. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YYYY-MM-DD', 'HH:MM (LST)', 'Zenith (deg)', 'Azimuth (deg)',\n",
       "       'ETR (Wh/m^2)', 'ETRN (Wh/m^2)', 'Glo Mod (Wh/m^2)', 'Glo Mod Unc (%)',\n",
       "       'Glo Mod Source', 'Dir Mod (Wh/m^2)', 'Dir Mod Unc (%)',\n",
       "       'Dir Mod Source', 'Dif Mod (Wh/m^2)', 'Dif Mod Unc (%)',\n",
       "       'Dif Mod Source', 'Meas Glo (Wh/m^2)', 'Meas Glo Flg',\n",
       "       'Meas Dir (Wh/m^2)', 'Meas Dir Flg', 'Meas Dif (Wh/m^2)',\n",
       "       'Meas Dif Flg', 'TotCC (10ths)', 'TotCC Flg', 'OpqCC (10ths)',\n",
       "       'OpqCC Flg', 'Dry Bulb (C)', 'Dry Bulb Flg', 'Dew Pnt (C)',\n",
       "       'Dew Pnt Flg', 'Rel Hum (%)', 'Rel Hum Flg', 'Baro Press (mbar)',\n",
       "       'Baro Press Flg', 'Wind Speed (m/s)', 'Wind Speed Flg',\n",
       "       'Wind Dir (deg)', 'Wind Dir Flg', 'Hor Vis (m)', 'Hor Vis Flg',\n",
       "       'Ceil Hgt (m)', 'Ceil Hgt Flg', 'Liq Precip Depth (mm)',\n",
       "       'Liq Precip Depth Flg', 'Liq Precip Quantity (hours)',\n",
       "       'Liq Precip Quantity Flg', 'Precip Wat (cm)', 'Precip Wat Flg',\n",
       "       'AOD (unitless)', 'AOD Flg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newark_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to filter out the features we do not need and also want make the dataframe index timestamps so we can merge with the other data sources down the road. \n",
    "\n",
    "Also we noticed that timestamps ranged from 1:00 to 24:59 instead of the conventional 00:00 to 23:59. We shifted these hours one hour to match the conventional approach and verified this in the **Timestamp Hour Sanity Check** Section of ```collect_data.ipynb```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def filter_feats(df):\n",
    "    return df.loc[:, ['YYYY-MM-DD', 'HH:MM (LST)', 'Glo Mod (Wh/m^2)' ]]\n",
    "\n",
    "def make_timestamp_str(row):\n",
    "    if str(row['HH:MM (LST)']) == '24:00':\n",
    "        string = str(pd.to_datetime(row['YYYY-MM-DD']) + pd.DateOffset(1))\n",
    "    else:\n",
    "        string = str(row['YYYY-MM-DD']) + ' ' + str(row['HH:MM (LST)'])\n",
    "    return str(pd.to_datetime(string))\n",
    "\n",
    "def apply_timestamps_to_index(df):\n",
    "    df.index = df.apply(make_timestamp_str, axis=1)\n",
    "    return df\n",
    "\n",
    "def preprocess(df):\n",
    "    df = filter_feats(df)\n",
    "    df = apply_timestamps_to_index(df)\n",
    "    df.drop(['YYYY-MM-DD', 'HH:MM (LST)'], axis=1, inplace=True)\n",
    "    df = df.iloc[23:-1]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glo Mod (Wh/m^2)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-02 00:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 01:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 02:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 03:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 04:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 05:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 06:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 07:00:00</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 08:00:00</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 09:00:00</th>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 10:00:00</th>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 11:00:00</th>\n",
       "      <td>372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Glo Mod (Wh/m^2)\n",
       "2006-01-02 00:00:00                 0\n",
       "2006-01-02 01:00:00                 0\n",
       "2006-01-02 02:00:00                 0\n",
       "2006-01-02 03:00:00                 0\n",
       "2006-01-02 04:00:00                 0\n",
       "2006-01-02 05:00:00                 0\n",
       "2006-01-02 06:00:00                 0\n",
       "2006-01-02 07:00:00                 0\n",
       "2006-01-02 08:00:00                12\n",
       "2006-01-02 09:00:00               140\n",
       "2006-01-02 10:00:00               286\n",
       "2006-01-02 11:00:00               372"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newark_df = preprocess(newark_df)\n",
    "newark_df.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then pushed the filtered solar data to the ```data/solar_filtered``` directory, and the data is now ready to be merged!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at ```collect_data.ipynb``` to see more details and this process being done for multiple locations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Historical and Forecasted Weather\n",
    "### Dark Sky API, Dark Sky Company, LLC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get weather data, we need to make api calls, so we will include the function here but will load the data from the csv that was already generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>cloudCover</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>icon</th>\n",
       "      <th>precipAccumulation</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>precipProbability</th>\n",
       "      <th>precipType</th>\n",
       "      <th>pressure</th>\n",
       "      <th>summary</th>\n",
       "      <th>temperature</th>\n",
       "      <th>uvIndex</th>\n",
       "      <th>visibility</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>windGust</th>\n",
       "      <th>windSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-02 00:00:00</th>\n",
       "      <td>36.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>31.40</td>\n",
       "      <td>0.81</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1022.75</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>36.81</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>246</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 01:00:00</th>\n",
       "      <td>35.79</td>\n",
       "      <td>0.22</td>\n",
       "      <td>30.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>clear-night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1022.80</td>\n",
       "      <td>Clear</td>\n",
       "      <td>35.79</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>234</td>\n",
       "      <td>2.22</td>\n",
       "      <td>1.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 02:00:00</th>\n",
       "      <td>35.67</td>\n",
       "      <td>0.32</td>\n",
       "      <td>30.43</td>\n",
       "      <td>0.81</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1023.57</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>35.67</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>216</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 03:00:00</th>\n",
       "      <td>35.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>30.64</td>\n",
       "      <td>0.82</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1023.57</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>35.49</td>\n",
       "      <td>0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>225</td>\n",
       "      <td>1.11</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 04:00:00</th>\n",
       "      <td>35.66</td>\n",
       "      <td>0.88</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>partly-cloudy-night</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1023.31</td>\n",
       "      <td>Mostly Cloudy</td>\n",
       "      <td>35.66</td>\n",
       "      <td>0</td>\n",
       "      <td>9.68</td>\n",
       "      <td>216</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     apparentTemperature  cloudCover  dewPoint  humidity  \\\n",
       "2006-01-02 00:00:00                36.81        0.82     31.40      0.81   \n",
       "2006-01-02 01:00:00                35.79        0.22     30.80      0.82   \n",
       "2006-01-02 02:00:00                35.67        0.32     30.43      0.81   \n",
       "2006-01-02 03:00:00                35.49        0.50     30.64      0.82   \n",
       "2006-01-02 04:00:00                35.66        0.88     31.25      0.84   \n",
       "\n",
       "                                    icon  precipAccumulation  precipIntensity  \\\n",
       "2006-01-02 00:00:00  partly-cloudy-night                 NaN              0.0   \n",
       "2006-01-02 01:00:00          clear-night                 NaN              0.0   \n",
       "2006-01-02 02:00:00  partly-cloudy-night                 NaN              0.0   \n",
       "2006-01-02 03:00:00  partly-cloudy-night                 NaN              0.0   \n",
       "2006-01-02 04:00:00  partly-cloudy-night                 NaN              0.0   \n",
       "\n",
       "                     precipProbability precipType  pressure        summary  \\\n",
       "2006-01-02 00:00:00                0.0        NaN   1022.75  Mostly Cloudy   \n",
       "2006-01-02 01:00:00                0.0        NaN   1022.80          Clear   \n",
       "2006-01-02 02:00:00                0.0        NaN   1023.57  Partly Cloudy   \n",
       "2006-01-02 03:00:00                0.0        NaN   1023.57  Partly Cloudy   \n",
       "2006-01-02 04:00:00                0.0        NaN   1023.31  Mostly Cloudy   \n",
       "\n",
       "                     temperature  uvIndex  visibility  windBearing  windGust  \\\n",
       "2006-01-02 00:00:00        36.81        0       10.00          246      1.86   \n",
       "2006-01-02 01:00:00        35.79        0       10.00          234      2.22   \n",
       "2006-01-02 02:00:00        35.67        0       10.00          216      2.01   \n",
       "2006-01-02 03:00:00        35.49        0        9.74          225      1.11   \n",
       "2006-01-02 04:00:00        35.66        0        9.68          216      0.66   \n",
       "\n",
       "                     windSpeed  \n",
       "2006-01-02 00:00:00       1.75  \n",
       "2006-01-02 01:00:00       1.86  \n",
       "2006-01-02 02:00:00       1.55  \n",
       "2006-01-02 03:00:00       0.81  \n",
       "2006-01-02 04:00:00       0.63  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newark_weather = pd.read_csv(\"data/weather/newark_weather.csv\", index_col='Unnamed: 0')\n",
    "newark_weather.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to drop the ```\"precipAccumulation\", \"precipType\", \"windGust\", \"icon\", \"summary\"``` columns as there are a good amount of NaN's and strings that will cause modeling problems later downstream."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the **Pull in Weather Data by Location** section of ```collect_data.ipynb``` for the full code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeled Direct Sunlight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to weather data from Darksky, we used an external source to generate the data, in this case it was a library called ```pysolar```. We can get clear sky radiation deterministically given a latitude, longitude, timestamp, timezone, and altitude."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_clear_sky_radiation(lat, lon, timestamp_str, tz):\n",
    "    dt = pd.to_datetime(timestamp_str)\n",
    "    tz_aware = datetime.datetime(dt.year, dt.month, dt.day, dt.hour, dt.minute, dt.second, 0, pytz.timezone('US/Eastern'))\n",
    "    altitude = get_altitude(lat, lon, aware)\n",
    "    watts_per_sq_meter = radiation.get_radiation_direct(tz_aware, altitude)\n",
    "    return watts_per_sq_meter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data source only would contain one column: ```'clear_sky'``` which would contain the deterministically predicted clear sky solar radiation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeled Global Horizontal Sunlight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we only use NREL data for our second question and for one location (the statue of liberty island), we download the data with a point query click from the web viewer and get global horizontal irradiance (ghi) every 30 mins for the years 2006-2010. Similar to the solar station data, there is a file for each year so we concatenate the dataframes for every year into one dataframe. Also, because the rest of our data is hourly, we first average the two ghi values for every hour in order to get Wh/m^2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GHI</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-01 00:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 01:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 02:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 03:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 04:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 05:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 06:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 07:00:00</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 08:00:00</th>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 09:00:00</th>\n",
       "      <td>48.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 10:00:00</th>\n",
       "      <td>126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-01 11:00:00</th>\n",
       "      <td>125.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       GHI\n",
       "Timestamp                 \n",
       "2006-01-01 00:00:00    0.0\n",
       "2006-01-01 01:00:00    0.0\n",
       "2006-01-01 02:00:00    0.0\n",
       "2006-01-01 03:00:00    0.0\n",
       "2006-01-01 04:00:00    0.0\n",
       "2006-01-01 05:00:00    0.0\n",
       "2006-01-01 06:00:00    0.0\n",
       "2006-01-01 07:00:00    0.0\n",
       "2006-01-01 08:00:00   15.0\n",
       "2006-01-01 09:00:00   48.5\n",
       "2006-01-01 10:00:00  126.0\n",
       "2006-01-01 11:00:00  125.5"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_nrel_data():\n",
    "    df = pd.DataFrame()\n",
    "    for year in range(2006, 2011):\n",
    "        year_df = pd.read_csv(\"data/statue_of_lib_data/1242368_40.69_-74.06_\" + str(year) + \".csv\", skiprows=2)\n",
    "        df = pd.concat([df, year_df])\n",
    "    df = df.groupby(by=[\"Year\", \"Month\", \"Day\", \"Hour\"]).mean().reset_index()\n",
    "    df['Timestamp'] = df['Year'].astype(str) + \"-\" + df['Month'].astype(str).apply(lambda x: x.zfill(2)) + \"-\" + df['Day'].astype(str).apply(lambda x: x.zfill(2)) + \" \" + df['Hour'].astype(str).apply(lambda x: x.zfill(2)) + \":00:00\" \n",
    "    df.set_index('Timestamp', inplace = True)\n",
    "    df.drop(columns=[\"Year\", \"Month\", \"Day\", \"Hour\", \"Minute\"], inplace=True)\n",
    "    return df\n",
    "\n",
    "stat_of_lib = get_nrel_data()\n",
    "stat_of_lib.head(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged Dataframe for Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the below function to merge our dataframes for our first question. Our first question only depends on solar, weather, and estimated direct solar data in order to predict solar irradiance.\n",
    "\n",
    "Our weather data is historical and forecasted weather data detailed above.\n",
    "\n",
    "\n",
    "Our estimated direct solar data (pysolar) such as data from ```newark_pysolar.csv``` represents merged solar and pysolar data (which is solar data with the addition of an estimate of the modeled direct sunlight. \n",
    "\n",
    "We additionally calculate and include some features that could help with predicting solar irradiance. We calculate and include the solar irradiance of yesterday, the average solar irradiance of last week, and the median solar irradiance of last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def merge_loc(loc_name):\n",
    "    weather = pd.read_csv('./data/weather/' + loc_name + '_weather.csv', index_col='Unnamed: 0')\n",
    "    pysolar = pd.read_csv('./data/pysolar/' + loc_name + '_pysolar.csv', index_col='Unnamed: 0')\n",
    "    pysolar = filter_feats(pysolar)\n",
    "    pysolar['yesterday'] = pysolar[\"Glo Mod (Wh/m^2)\"].shift(24).fillna(0)\n",
    "    \n",
    "    pysolar[\"avg_last_week\"] = pysolar['yesterday']\n",
    "    for i in range(2, 8):\n",
    "        pysolar[\"avg_last_week\"] += pysolar[\"Glo Mod (Wh/m^2)\"].shift(24*i)\n",
    "    pysolar[\"avg_last_week\"] = pysolar[\"avg_last_week\"] / 7\n",
    "    \n",
    "    pysolar[\"median_week_1\"] = pysolar['yesterday']\n",
    "    for i in range(2, 8):\n",
    "        pysolar[\"median_week_\" + str(i)] = pysolar[\"Glo Mod (Wh/m^2)\"].shift(24*i)\n",
    "    last_week = pysolar[['median_week_' + str(i) for i in range(1, 8)]]\n",
    "    medians = last_week.median(axis=1)\n",
    "    pysolar.drop(columns=['median_week_' + str(i) for i in range(1, 8)], inplace=True)\n",
    "    pysolar['last_week_median'] = medians\n",
    "    \n",
    "    df = weather.merge(pysolar, left_index=True, right_index=True)\n",
    "    df.to_csv('./data/' + loc_name + '_merged.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once saved in merged, we verify that our data is merged correctly with newark!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apparentTemperature</th>\n",
       "      <th>cloudCover</th>\n",
       "      <th>dewPoint</th>\n",
       "      <th>humidity</th>\n",
       "      <th>precipIntensity</th>\n",
       "      <th>precipProbability</th>\n",
       "      <th>pressure</th>\n",
       "      <th>temperature</th>\n",
       "      <th>uvIndex</th>\n",
       "      <th>visibility</th>\n",
       "      <th>windBearing</th>\n",
       "      <th>windSpeed</th>\n",
       "      <th>Glo Mod (Wh/m^2)</th>\n",
       "      <th>clear_sky</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>avg_last_week</th>\n",
       "      <th>last_week_median</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2006-01-02 00:00:00</th>\n",
       "      <td>36.81</td>\n",
       "      <td>0.82</td>\n",
       "      <td>31.40</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.75</td>\n",
       "      <td>36.81</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>246</td>\n",
       "      <td>1.75</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 01:00:00</th>\n",
       "      <td>35.79</td>\n",
       "      <td>0.22</td>\n",
       "      <td>30.80</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1022.80</td>\n",
       "      <td>35.79</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>234</td>\n",
       "      <td>1.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 02:00:00</th>\n",
       "      <td>35.67</td>\n",
       "      <td>0.32</td>\n",
       "      <td>30.43</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1023.57</td>\n",
       "      <td>35.67</td>\n",
       "      <td>0</td>\n",
       "      <td>10.00</td>\n",
       "      <td>216</td>\n",
       "      <td>1.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 03:00:00</th>\n",
       "      <td>35.49</td>\n",
       "      <td>0.50</td>\n",
       "      <td>30.64</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1023.57</td>\n",
       "      <td>35.49</td>\n",
       "      <td>0</td>\n",
       "      <td>9.74</td>\n",
       "      <td>225</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2006-01-02 04:00:00</th>\n",
       "      <td>35.66</td>\n",
       "      <td>0.88</td>\n",
       "      <td>31.25</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1023.31</td>\n",
       "      <td>35.66</td>\n",
       "      <td>0</td>\n",
       "      <td>9.68</td>\n",
       "      <td>216</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     apparentTemperature  cloudCover  dewPoint  humidity  \\\n",
       "2006-01-02 00:00:00                36.81        0.82     31.40      0.81   \n",
       "2006-01-02 01:00:00                35.79        0.22     30.80      0.82   \n",
       "2006-01-02 02:00:00                35.67        0.32     30.43      0.81   \n",
       "2006-01-02 03:00:00                35.49        0.50     30.64      0.82   \n",
       "2006-01-02 04:00:00                35.66        0.88     31.25      0.84   \n",
       "\n",
       "                     precipIntensity  precipProbability  pressure  \\\n",
       "2006-01-02 00:00:00              0.0                0.0   1022.75   \n",
       "2006-01-02 01:00:00              0.0                0.0   1022.80   \n",
       "2006-01-02 02:00:00              0.0                0.0   1023.57   \n",
       "2006-01-02 03:00:00              0.0                0.0   1023.57   \n",
       "2006-01-02 04:00:00              0.0                0.0   1023.31   \n",
       "\n",
       "                     temperature  uvIndex  visibility  windBearing  windSpeed  \\\n",
       "2006-01-02 00:00:00        36.81        0       10.00          246       1.75   \n",
       "2006-01-02 01:00:00        35.79        0       10.00          234       1.86   \n",
       "2006-01-02 02:00:00        35.67        0       10.00          216       1.55   \n",
       "2006-01-02 03:00:00        35.49        0        9.74          225       0.81   \n",
       "2006-01-02 04:00:00        35.66        0        9.68          216       0.63   \n",
       "\n",
       "                     Glo Mod (Wh/m^2)  clear_sky  yesterday  avg_last_week  \\\n",
       "2006-01-02 00:00:00                 0        0.0        0.0            NaN   \n",
       "2006-01-02 01:00:00                 0        0.0        0.0            NaN   \n",
       "2006-01-02 02:00:00                 0        0.0        0.0            NaN   \n",
       "2006-01-02 03:00:00                 0        0.0        0.0            NaN   \n",
       "2006-01-02 04:00:00                 0        0.0        0.0            NaN   \n",
       "\n",
       "                     last_week_median  \n",
       "2006-01-02 00:00:00               0.0  \n",
       "2006-01-02 01:00:00               0.0  \n",
       "2006-01-02 02:00:00               0.0  \n",
       "2006-01-02 03:00:00               0.0  \n",
       "2006-01-02 04:00:00               0.0  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newark_df = pd.read_csv('./data/merged/newark_merged.csv', index_col='Unnamed: 0')\n",
    "newark_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merged Dataframe for Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The approach with this question is not tradional in the sense that it does not use a large merged dataset. This question instead has 11 different solar dataframes each representing a different station and creates a concatenated dataframe of data from a given timestamp. So our data we fit our model with changes at runtime depending on our specified timestamp.\n",
    "\n",
    "We did this instead of a large dataframe with everything as that data would most likely not fit in memory on datahub and our dataframes were all indexed by the same timestamps which would conflict if we tried to stack them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We only need to collect solar irradiance data (```'Glo Mod (Wh/m^2)'```) as we will use a spatial model to try to predict solar irradiance and are not relying on physical features such as weather or temporal conditions. We also include names in order to merge with our station data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bridgeport_df = pd.read_csv('data/solar_filtered/bridgeport_solar_filtered.csv', index_col='Unnamed: 0').loc[:, ['Glo Mod (Wh/m^2)']]\n",
    "jfk_df =pd.read_csv('data/solar_filtered/jfk_solar_filtered.csv', index_col='Unnamed: 0').loc[:, ['Glo Mod (Wh/m^2)']]\n",
    "laguardia_df = pd.read_csv('data/solar_filtered/laguardia_solar_filtered.csv', index_col='Unnamed: 0').loc[:, ['Glo Mod (Wh/m^2)']]\n",
    "newark_df = pd.read_csv('data/solar_filtered/newark_solar_filtered.csv', index_col='Unnamed: 0').loc[:, ['Glo Mod (Wh/m^2)']]\n",
    "li_macarthur_df = pd.read_csv('data/solar_filtered/li_macarthur_solar_filtered.csv', index_col='Unnamed: 0').loc[:, ['Glo Mod (Wh/m^2)']]\n",
    "p_duchess_df = pd.read_csv('data/solar_filtered/p_duchess_filtered.csv', index_col='Unnamed: 0').loc[:, ['Glo Mod (Wh/m^2)']]\n",
    "stewart_df =pd.read_csv('data/solar_filtered/stewart_filtered.csv', index_col='Unnamed: 0').loc[:, ['Glo Mod (Wh/m^2)']]\n",
    "white_plains_df = pd.read_csv('data/solar_filtered/white_plains_filtered.csv', index_col='Unnamed: 0').loc[:, ['Glo Mod (Wh/m^2)']]\n",
    "republic_df = pd.read_csv('data/solar_filtered/republic_filtered.csv', index_col='Unnamed: 0').loc[:, ['Glo Mod (Wh/m^2)']]\n",
    "caldwell_df = pd.read_csv('data/solar_filtered/caldwell_filtered.csv', index_col='Unnamed: 0').loc[:, ['Glo Mod (Wh/m^2)']]\n",
    "danbury_df = pd.read_csv('data/solar_filtered/danbury_filtered.csv', index_col='Unnamed: 0').loc[:, ['Glo Mod (Wh/m^2)']]\n",
    "\n",
    "bridgeport_df['name'] = \"Bridgeport\"\n",
    "jfk_df['name'] = \"JFK\"\n",
    "laguardia_df['name'] = \"LAG\"\n",
    "newark_df['name'] = \"EWR\"\n",
    "li_macarthur_df['name'] = \"Macarthur\"\n",
    "p_duchess_df['name'] = \"p_duchess\"\n",
    "stewart_df['name'] = \"stewart\"\n",
    "white_plains_df['name'] = \"white_plains\"\n",
    "republic_df['name'] = \"republic\"\n",
    "caldwell_df['name'] = \"caldwell\"\n",
    "danbury_df['name'] = \"danbury\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We additonally pull in stations data that is metadata from the NREL solar data sources that includes lats and longs that we merge with our dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Macarthur</td>\n",
       "      <td>40.783</td>\n",
       "      <td>-73.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EWR</td>\n",
       "      <td>40.717</td>\n",
       "      <td>-74.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JFK</td>\n",
       "      <td>40.650</td>\n",
       "      <td>-73.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LAG</td>\n",
       "      <td>40.783</td>\n",
       "      <td>-70.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bridgeport</td>\n",
       "      <td>41.183</td>\n",
       "      <td>-73.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>p_duchess</td>\n",
       "      <td>41.633</td>\n",
       "      <td>-73.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>stewart</td>\n",
       "      <td>41.500</td>\n",
       "      <td>-74.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>white_plains</td>\n",
       "      <td>41.067</td>\n",
       "      <td>-73.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>republic</td>\n",
       "      <td>40.717</td>\n",
       "      <td>-73.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>caldwell</td>\n",
       "      <td>40.883</td>\n",
       "      <td>-74.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>danbury</td>\n",
       "      <td>41.240</td>\n",
       "      <td>-73.280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>stat_of_lib</td>\n",
       "      <td>40.690</td>\n",
       "      <td>-74.060</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            name     lat     lon\n",
       "0      Macarthur  40.783 -73.100\n",
       "1            EWR  40.717 -74.183\n",
       "2            JFK  40.650 -73.800\n",
       "3            LAG  40.783 -70.883\n",
       "4     Bridgeport  41.183 -73.150\n",
       "5      p_duchess  41.633 -73.883\n",
       "6        stewart  41.500 -74.100\n",
       "7   white_plains  41.067 -73.717\n",
       "8       republic  40.717 -73.417\n",
       "9       caldwell  40.883 -74.283\n",
       "10       danbury  41.240 -73.280\n",
       "11   stat_of_lib  40.690 -74.060"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = pd.read_csv(\"stations.csv\").drop(columns=[\"id\", \"altitude (m)\"])\n",
    "stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set an example timestamp to ensure our merged data looks good!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ts = \"2008-06-02 10:00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Glo Mod (Wh/m^2)</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>802</td>\n",
       "      <td>41.183</td>\n",
       "      <td>-73.150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>788</td>\n",
       "      <td>40.650</td>\n",
       "      <td>-73.800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>777</td>\n",
       "      <td>40.783</td>\n",
       "      <td>-70.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>793</td>\n",
       "      <td>40.717</td>\n",
       "      <td>-74.183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>803</td>\n",
       "      <td>40.783</td>\n",
       "      <td>-73.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>793</td>\n",
       "      <td>41.633</td>\n",
       "      <td>-73.883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>793</td>\n",
       "      <td>41.500</td>\n",
       "      <td>-74.100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>799</td>\n",
       "      <td>41.067</td>\n",
       "      <td>-73.717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>795</td>\n",
       "      <td>40.717</td>\n",
       "      <td>-73.417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>795</td>\n",
       "      <td>40.883</td>\n",
       "      <td>-74.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800</td>\n",
       "      <td>41.240</td>\n",
       "      <td>-73.280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Glo Mod (Wh/m^2)     lat     lon\n",
       "0               802  41.183 -73.150\n",
       "0               788  40.650 -73.800\n",
       "0               777  40.783 -70.883\n",
       "0               793  40.717 -74.183\n",
       "0               803  40.783 -73.100\n",
       "0               793  41.633 -73.883\n",
       "0               793  41.500 -74.100\n",
       "0               799  41.067 -73.717\n",
       "0               795  40.717 -73.417\n",
       "0               795  40.883 -74.283\n",
       "0               800  41.240 -73.280"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data = pd.DataFrame()\n",
    "all_data = pd.concat([all_data, stations.merge(bridgeport_df[bridgeport_df.index == ts], on=\"name\")]).drop(columns=\"name\")\n",
    "all_data = pd.concat([all_data, stations.merge(jfk_df[jfk_df.index == ts], on=\"name\")]).drop(columns=\"name\")\n",
    "all_data = pd.concat([all_data, stations.merge(laguardia_df[laguardia_df.index == ts], on=\"name\")]).drop(columns=\"name\")\n",
    "all_data = pd.concat([all_data, stations.merge(newark_df[newark_df.index == ts], on=\"name\")]).drop(columns=\"name\")\n",
    "all_data = pd.concat([all_data, stations.merge(li_macarthur_df[li_macarthur_df.index == ts], on=\"name\")]).drop(columns=\"name\")\n",
    "all_data = pd.concat([all_data, stations.merge(p_duchess_df[p_duchess_df.index == ts], on=\"name\")]).drop(columns=\"name\")\n",
    "all_data = pd.concat([all_data, stations.merge(stewart_df[stewart_df.index == ts], on=\"name\")]).drop(columns=\"name\")\n",
    "all_data = pd.concat([all_data, stations.merge(white_plains_df[white_plains_df.index == ts], on=\"name\")]).drop(columns=\"name\")\n",
    "all_data = pd.concat([all_data, stations.merge(republic_df[republic_df.index == ts], on=\"name\")]).drop(columns=\"name\")\n",
    "all_data = pd.concat([all_data, stations.merge(caldwell_df[caldwell_df.index == ts], on=\"name\")]).drop(columns=\"name\")\n",
    "all_data = pd.concat([all_data, stations.merge(danbury_df[danbury_df.index == ts], on=\"name\")]).drop(columns=\"name\")\n",
    "all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For June 2nd, 2008 at 10am, these are the measured solar values at the 11 different stations that we then can plug into our spatial model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Summary and Exploratory Data Analysis (10 points)\n",
    "\n",
    "In this section you should provide a tour through some of the basic trends and patterns in your data.  This includes providing initial plots to summarize the data, such as box plots, histograms, trends over time, scatter plots relating one variable or another.  \n",
    "\n",
    "[Chapter 6](https://www.textbook.ds100.org/ch/06/viz_intro.html) of the DS100 textbook might be helpful for providing ideas for visualizations that describe your data.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting and Prediction Modeling (25 points)\n",
    "\n",
    "This section is where the rubber meets the road.  In it you must:\n",
    "1. Explore at least 3 prediction modeling approaches, ranging from the simple (e.g. linear regression, KNN) to the complex (e.g. SVM, random forests, Lasso).  \n",
    "2. Motivate all your modeling decisions.  This includes parameter choices (e.g., how many folds in k-fold cross validation, what time window you use for averaging your data) as well as model form (e.g., If you use regression trees, why?  If you include nonlinear features in a regression model, why?). \n",
    "1. Carefully describe your cross validation and model selection process. \n",
    "3. Evaluate your models' performance.  How much total error is there?  Where do you see bias?  Where do you see variance? \n",
    "4. Very carefully document your workflow.  We will be reading a lot of projects, so we need you to explain each basic step in your analysis.  \n",
    "5. Seek opportunities to compartmentalize the details of the workflow into functions.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpretation and Conclusions (20 points)\n",
    "In this section you must relate your modeling and forecasting results to your original research question.  You must \n",
    "1. Put your numeric or TRUE/FALSE answers into context.  What do the answers mean? What advice would you give a decision maker on the basis of your results?  Why should the reader care about your results?\n",
    "2. Discuss caveats and / or reasons your results might be flawed.  No model is perfect, and understanding a model's imperfections is extremely important for the purpose of knowing how to interpret your results.  Often, we know the model output is wrong but we can assign a direction for its bias.  This helps to understand whether or not your answers are conservative.  \n",
    "\n",
    "Shoot for 500-1000 words for this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
